{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロダクト開発演習\n",
    "\n",
    "## 概要\n",
    "\n",
    "### テーマ\n",
    "\n",
    "高解像度の画像への変換（課題番号001）\n",
    "\n",
    "### 使用したモデル\n",
    "\n",
    "**SRCNN**\n",
    "\n",
    "* super-resolution CNN の略称。\n",
    "* 登場自体は2015年で、超解像度を目的とするCNNの中では比較的古く、小さいモデルになる。\n",
    "* このネットワークでは入力される画像サイズと出力される画像サイズは同じである（拡大は行われない）\n",
    "* その小ささからちゃんとしたGPUがなくても動くとのことで、今回採用した。\n",
    "* 参照論文：https://arxiv.org/pdf/1501.00092.pdf\n",
    "\n",
    "### 使用したデータセット\n",
    "\n",
    "**STL-10**\n",
    "\n",
    "* スタンフォード大学が公開している10クラスの画像データセット。\n",
    "  * DL元サイト：https://cs.stanford.edu/~acoates/stl10/\n",
    "  * 学習用データ、テスト用データ、ラベルなしデータに分かれている。\n",
    "  * 学習用データは1クラスにつき500枚。\n",
    "  * テストデータは1クラスにつき800枚。\n",
    "  * ラベルなしデータは10万枚ある。\n",
    "  * CIFAR10 と比較すると、画像サイズが96×96であるため、より鮮明なデータとして扱える \n",
    "* 今回はモデルに読み込ませる低解像度の画像を高解像度の画像から作成するため、<br>ある程度低解像度化しても元の画像の特徴が潰れにくくなることを期待して採用した。\n",
    "* 提出の際にデータが大きくなりすぎるため、今回は元画像の学習用データ5000枚から500枚を選んで学習に使用した。\n",
    "  * 5000枚使ったものについては結果だけ記載\n",
    "* テストにはテストデータの最初の画像を1枚使用した。\n",
    "* バイナリまたはMatlabファイルの形でDLすることになるため、展開用のコードとして`STL10.py`を添付"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 低解像度の画像の準備について\n",
    "\n",
    "* 元となる画像を縮小し、古典的な手法（今回はOpenCVのデフォルトであるバイリニア補間を採用）で拡大したものを<br>低解像度の画像として扱った\n",
    "\n",
    "## 評価関数について\n",
    "\n",
    "* PSNR（ピーク信号対雑音比）を採用\n",
    "* 数式としては以下になり、30db以上であれば綺麗に見えるとのこと\n",
    "\n",
    "$$ PSNR =10 log_{10} \\frac{MAX^2}{MSE} \\\\ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as kl\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# 乱数シードを指定\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "# GPUが利用できることを確認\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRCNN\n",
    "class SRCNN(tf.keras.Model):\n",
    "    def __init__(self, h, w):\n",
    "        super(SRCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = kl.Conv2D(64, 3, padding='same', activation='relu', input_shape=(None, h, w, 3))\n",
    "        self.conv2 = kl.Conv2D(32, 3, padding='same', activation='relu')\n",
    "        self.conv3 = kl.Conv2D(3, 3, padding='same', activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        h1 = self.conv1(x)\n",
    "        h2 = self.conv2(h1)\n",
    "        h3 = self.conv3(h2)\n",
    "\n",
    "        return h3\n",
    "\n",
    "\n",
    "# 学習\n",
    "class trainer(object):\n",
    "    def __init__(self, h, w):\n",
    "        self.model = SRCNN(h, w)\n",
    "\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                            loss=tf.keras.losses.MeanSquaredError(),\n",
    "                            metrics=[self.psnr])\n",
    "\n",
    "    def train(self, lr_imgs, hr_imgs, out_path, batch_size, epochs):\n",
    "        # 学習\n",
    "        his = self.model.fit(lr_imgs, hr_imgs, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        print(\"___Training finished\\n\\n\")\n",
    "\n",
    "        # パラメータ保存\n",
    "        print(\"___Saving parameter...\")\n",
    "        self.model.save_weights(out_path)\n",
    "        print(\"___Successfully completed\\n\\n\")\n",
    "\n",
    "        return his, self.model\n",
    "\n",
    "    # PSNR(ピーク信号対雑音比)\n",
    "    \"\"\"\n",
    "    def psnr(self, h3, hr_imgs):\n",
    "        return -10 * tf.math.log(tf.keras.metrics.Mean()(kl.Flatten()((h3 - hr_imgs))**2)) / np.log(10)\n",
    "    \"\"\"\n",
    "    def psnr(self, h3, hr_imgs):\n",
    "        return tf.image.psnr(h3, hr_imgs, max_val=1.0)\n",
    "\n",
    "\n",
    "# データセット作成\n",
    "def create_dataset(data_dir, mag):\n",
    "    print(\"\\n___Creating a dataset...\")\n",
    "\n",
    "    prc = ['/', '-', '\\\\', '|']\n",
    "    cnt = 0\n",
    "\n",
    "    # 画像データの個数\n",
    "    print(\"Number of image in a directory: {}\".format(len(os.listdir(data_dir))))\n",
    "\n",
    "    lr_imgs = []\n",
    "    hr_imgs = []\n",
    "\n",
    "    for c in os.listdir(data_dir):\n",
    "        d = os.path.join(data_dir, c)\n",
    "\n",
    "\n",
    "        # 高解像度画像読込\n",
    "        img = cv2.imread(d)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 低解像度画像作成\n",
    "        img_low = cv2.resize(img, (int(img.shape[0] / mag), int(img.shape[1] / mag)))\n",
    "        img_low = cv2.resize(img_low, (int(img.shape[0]), int(img.shape[1])))\n",
    "\n",
    "        lr_imgs.append(img_low)\n",
    "        hr_imgs.append(img)\n",
    "        \n",
    "        # データセットの一部をサンプルとして表示\n",
    "        if cnt ==0:\n",
    "            print(\"default Image sample\")\n",
    "            plt.imshow( img )\n",
    "            plt.show()\n",
    "            print(\"low-resolution Image sample\")\n",
    "            plt.imshow( img_low )\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        print(\"\\rLoading a LR-images and HR-images...{}    ({} / {})\".format(prc[cnt % 4], cnt, len(os.listdir(data_dir))), end='')\n",
    "\n",
    "    print(\"\\rLoading a LR-images and HR-images...Done    ({} / {})\".format(cnt, len(os.listdir(data_dir))), end='')\n",
    "    \n",
    "    he = len(img_low)\n",
    "    wi = len(img_low[0])\n",
    "\n",
    "    # 正規化\n",
    "    \n",
    "    lr_imgs = tf.convert_to_tensor(lr_imgs, np.float32)\n",
    "    lr_imgs /= 255\n",
    "    hr_imgs = tf.convert_to_tensor(hr_imgs, np.float32)\n",
    "    hr_imgs /= 255\n",
    "\n",
    "    print(\"\\n___Successfully completed\\n\")\n",
    "    \n",
    "    return lr_imgs, hr_imgs, he, wi\n",
    "\n",
    "\n",
    "# PSNR, 損失値グラフ出力\n",
    "def graph_output(history):\n",
    "    # PSNRグラフ\n",
    "    plt.plot(history.history['psnr'])\n",
    "    plt.title('Model PSNR')\n",
    "    plt.ylabel('PSNR')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # 損失値グラフ\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def Training(data_dir, out, batch_size, epoch, mag):\n",
    "    # コマンドラインオプション作成\n",
    "    \"\"\"\n",
    "    parser = arg.ArgumentParser(description='Super-resolution CNN training')\n",
    "    data_dir　：画像フォルダパスの指定(未指定ならエラー)\n",
    "    out　　 　：パラメータの保存先指定\n",
    "    batch_size：ミニバッチサイズの指定\n",
    "    epoch　　 ：学習回数の指定\n",
    "    mag　　　 ：縮小倍率の指定\n",
    "    \"\"\"\n",
    "\n",
    "    # 画像フォルダパスが未指定の場合ストップ\n",
    "    if data_dir is None:\n",
    "        print(\"\\nException: Folder not specified.\\n\")\n",
    "        sys.exit()\n",
    "    # 存在しない画像フォルダ指定時の場合ストップ\n",
    "    if os.path.exists(data_dir) is False:\n",
    "        print(\"\\nException: Folder \\\"{}\\\" is not found.\\n\".format(data_dir))\n",
    "        sys.exit()\n",
    "    # 縮小倍率に0が入力された時の場合ストップ\n",
    "    if mag == 0:\n",
    "        print(\"\\nException: Invalid value has been entered.\\n\")\n",
    "        sys.exit()\n",
    "\n",
    "    # 出力フォルダの作成(フォルダが存在する場合は作成しない)\n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    out_path = os.path.join(out, \"./srcnn.h5\")\n",
    "\n",
    "    # 設定情報出力\n",
    "    print(\"=== Setting information ===\")\n",
    "    print(\"# Images folder: {}\".format(os.path.abspath(data_dir)))\n",
    "    print(\"# Output folder: {}\".format(out_path))\n",
    "    print(\"# Minibatch-size: {}\".format(batch_size))\n",
    "    print(\"# Epoch: {}\".format(epoch))\n",
    "    print(\"# Magnification: {}\".format(mag))\n",
    "\n",
    "    # データセット作成\n",
    "    lr_imgs, hr_imgs, he, wi = create_dataset(data_dir, mag)\n",
    "    \n",
    "    print(\"# Height: {}\".format(he))\n",
    "    print(\"# Width: {}\".format(wi))\n",
    "    print(\"===========================\\n\")\n",
    "\n",
    "    # 学習開始\n",
    "    print(\"___Start training...\")\n",
    "    Trainer = trainer(he, wi)\n",
    "    his, model = Trainer.train(lr_imgs, hr_imgs, out_path=out_path, batch_size=batch_size, epochs=epoch)\n",
    "\n",
    "    # PSNR, 損失値グラフ出力、保存\n",
    "    graph_output(his)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
